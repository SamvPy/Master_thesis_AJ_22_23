{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# Models\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier as lgbm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# preprocessors\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif, SelectKBest, SelectFromModel, RFE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Samplers\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# metrics and splitters\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# utils\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib_venn as venn\n",
    "\n",
    "# progress bar\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import utils_ML as uml\n",
    "import AtlasAnalysisFunctions as AAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 2.6564102564102563, 9: 0.7194444444444444, 11: 1.3282051282051281, 3: 2.3022222222222224, 1: 0.3453333333333333, 7: 3.453333333333333, 5: 1.4388888888888889, 0: 0.4427350427350427, 8: 1.5014492753623188, 12: 1.4388888888888889, 10: 1.3282051282051281, 6: 0.5755555555555556, 13: 1.817543859649123, 14: 3.453333333333333, 4: 0.8222222222222222}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../PEMatrix/norm_NSAF_data2.csv\", index_col = \"assay_id\")\n",
    "meta = pd.read_csv(\"../../Metadata/unified_metadata.csv\")\n",
    "meta = meta[meta.assay_id.isin(data.index)]\n",
    "\n",
    "groups = pd.read_csv(\"../../Metadata/group_cells_annotation.csv\", sep =\";\", index_col=\"Unnamed: 0\")\n",
    "meta[\"Group\"] = meta.cell_line.apply(lambda x: groups[groups.cell_line == x][\"group\"].values[0])\n",
    "meta = meta.set_index(\"assay_id\")\n",
    "\n",
    "data.sort_index(inplace=True)\n",
    "meta.sort_index(inplace=True)\n",
    "\n",
    "target_encoder = LabelEncoder()\n",
    "targets = target_encoder.fit_transform(meta.Group)\n",
    "unique_labels = pd.Series(targets).unique()\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=unique_labels, y=targets)\n",
    "\n",
    "weights = {unique_labels[i]: class_weights[i] for i in range(len(unique_labels))}\n",
    "print(weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is better? \n",
    "- using log transformed data\n",
    "- exponentiating them\n",
    "- Minmax vs standardscaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking will be done on 50% occurence filtering with SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = np.exp2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c60727614d4d94a9a2c7bd7e54e9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# exponentiated data\n",
    "\n",
    "f = IntProgress(min=0, max= 10 * 3) \n",
    "display(f)\n",
    "\n",
    "splitter = StratifiedKFold(10, shuffle = True)\n",
    "models = [LogisticRegression(max_iter=10000), SVC(), RandomForestClassifier()]\n",
    "\n",
    "fold=0\n",
    "for train, test in splitter.split(exp_data, targets):\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "    X_train = exp_data.iloc[train,:]\n",
    "    Y_train = targets[train]\n",
    "    X_test = exp_data.iloc[test,:]\n",
    "    Y_test = targets[test]\n",
    "\n",
    "    preprocessor = Pipeline(steps=[\n",
    "        ('filter', uml.FilterByOccurence()),\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0))\n",
    "    ])\n",
    "\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    standard_scaler = StandardScaler()\n",
    "\n",
    "    preprocessor.fit(X_train)\n",
    "    X_train_preprocessed = preprocessor.transform(X_train)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)    \n",
    "\n",
    "    minmax_scaler.fit(X_train_preprocessed)\n",
    "    standard_scaler.fit(X_train_preprocessed)\n",
    "\n",
    "    # Minmax\n",
    "    X_train_mm = minmax_scaler.transform(X_train_preprocessed)\n",
    "    X_test_mm = minmax_scaler.transform(X_test_preprocessed)\n",
    "    X_train_mm, Y_train_mm = SMOTETomek().fit_resample(X_train_mm, Y_train)\n",
    "\n",
    "\n",
    "    # Standard scaler\n",
    "    X_train_std = standard_scaler.transform(X_train_preprocessed)\n",
    "    X_test_std = standard_scaler.transform(X_test_preprocessed)\n",
    "    X_train_std, Y_train_std = SMOTETomek().fit_resample(X_train_std, Y_train)\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        # Minmax\n",
    "        model.fit(X_train_mm, Y_train_mm)\n",
    "        Y_pred_mm = model.predict(X_test_mm)\n",
    "\n",
    "        micro_f1, macro_f1, weighted_f1, cm = uml.scoring_functions(Y_pred=Y_pred_mm, Y_test=Y_test, labels=unique_labels)\n",
    "        results_df = pd.DataFrame({\"model\": [type(model).__name__], \"fold\": [fold], \"micro_f1\": [micro_f1],\n",
    "                                            \"macro_f1\": [macro_f1], \"weighted_f1\": [weighted_f1] ,\"cm\": [cm], \"scaler\": [\"minmaxScaler\"],\n",
    "                                            \"oversampler\": [\"SMOTETomek\"], 'data_type': [\"exp_data\"]})\n",
    "        uml.save_results(results_df, \"scaling_comparison\")\n",
    "\n",
    "        # standard scaler\n",
    "        model.fit(X_train_std, Y_train_std)\n",
    "        Y_pred_std = model.predict(X_test_std)\n",
    "\n",
    "        micro_f1, macro_f1, weighted_f1, cm = uml.scoring_functions(Y_pred=Y_pred_std, Y_test=Y_test, labels=unique_labels)\n",
    "        results_df = pd.DataFrame({\"model\": [type(model).__name__], \"fold\": [fold], \"micro_f1\": [micro_f1],\n",
    "                                            \"macro_f1\": [macro_f1], \"weighted_f1\": [weighted_f1] ,\"cm\": [cm], \"scaler\": [\"standardScaler\"],\n",
    "                                            \"oversampler\": [\"SMOTETomek\"], \"data_type\": [\"exp_data\"]})\n",
    "        uml.save_results(results_df, \"scaling_comparison\")\n",
    "\n",
    "        f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc14b03ef9a42d7a4926dcd407c50fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log transform data\n",
    "\n",
    "f = IntProgress(min=0, max= 10 * 3) \n",
    "display(f)\n",
    "\n",
    "splitter = StratifiedKFold(10, shuffle = True)\n",
    "models = [LogisticRegression(max_iter=10000), SVC(), RandomForestClassifier()]\n",
    "\n",
    "fold=0\n",
    "for train, test in splitter.split(data, targets):\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "    X_train = data.iloc[train,:]\n",
    "    Y_train = targets[train]\n",
    "    X_test = data.iloc[test,:]\n",
    "    Y_test = targets[test]\n",
    "\n",
    "    preprocessor = Pipeline(steps=[\n",
    "        ('filter', uml.FilterByOccurence()),\n",
    "        ('imputer', uml.LowestValueImputer())\n",
    "    ])\n",
    "\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    standard_scaler = StandardScaler()\n",
    "\n",
    "    preprocessor.fit(X_train)\n",
    "    X_train_preprocessed = preprocessor.transform(X_train)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)    \n",
    "\n",
    "    minmax_scaler.fit(X_train_preprocessed)\n",
    "    standard_scaler.fit(X_train_preprocessed)\n",
    "\n",
    "    # Minmax\n",
    "    X_train_mm = minmax_scaler.transform(X_train_preprocessed)\n",
    "    X_test_mm = minmax_scaler.transform(X_test_preprocessed)\n",
    "    X_train_mm, Y_train_mm = SMOTETomek().fit_resample(X_train_mm, Y_train)\n",
    "\n",
    "\n",
    "    # Standard scaler\n",
    "    X_train_std = standard_scaler.transform(X_train_preprocessed)\n",
    "    X_test_std = standard_scaler.transform(X_test_preprocessed)\n",
    "    X_train_std, Y_train_std = SMOTETomek().fit_resample(X_train_std, Y_train)\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        # Minmax\n",
    "        model.fit(X_train_mm, Y_train_mm)\n",
    "        Y_pred_mm = model.predict(X_test_mm)\n",
    "\n",
    "        micro_f1, macro_f1, weighted_f1, cm = uml.scoring_functions(Y_pred=Y_pred_mm, Y_test=Y_test, labels=unique_labels)\n",
    "        results_df = pd.DataFrame({\"model\": [type(model).__name__], \"fold\": [fold], \"micro_f1\": [micro_f1],\n",
    "                                            \"macro_f1\": [macro_f1], \"weighted_f1\": [weighted_f1] ,\"cm\": [cm], \"scaler\": [\"minmaxScaler\"],\n",
    "                                            \"oversampler\": [\"SMOTETomek\"], \"data_type\": [\"log-transformed\"]})\n",
    "        uml.save_results(results_df, \"scaling_comparison\")\n",
    "\n",
    "        # standard scaler\n",
    "        model.fit(X_train_std, Y_train_std)\n",
    "        Y_pred_std = model.predict(X_test_std)\n",
    "\n",
    "        micro_f1, macro_f1, weighted_f1, cm = uml.scoring_functions(Y_pred=Y_pred_std, Y_test=Y_test, labels=unique_labels)\n",
    "        results_df = pd.DataFrame({\"model\": [type(model).__name__], \"fold\": [fold], \"micro_f1\": [micro_f1],\n",
    "                                            \"macro_f1\": [macro_f1], \"weighted_f1\": [weighted_f1] ,\"cm\": [cm], \"scaler\": [\"standardScaler\"],\n",
    "                                            \"oversampler\": [\"SMOTETomek\"], \"data_type\": [\"log-transformed\"]})\n",
    "        uml.save_results(results_df, \"scaling_comparison\")\n",
    "\n",
    "        f.value += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ionbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
